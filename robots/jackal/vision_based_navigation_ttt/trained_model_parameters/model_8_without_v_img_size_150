Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 150, 150, 2  0           []                               
                                )]                                                                
                                                                                                  
 conv2d (Conv2D)                (None, 148, 148, 64  1216        ['input_1[0][0]']                
                                )                                                                 
                                                                                                  
 average_pooling2d (AveragePool  (None, 74, 74, 64)  0           ['conv2d[0][0]']                 
 ing2D)                                                                                           
                                                                                                  
 conv2d_1 (Conv2D)              (None, 72, 72, 32)   18464       ['average_pooling2d[0][0]']      
                                                                                                  
 average_pooling2d_1 (AveragePo  (None, 36, 36, 32)  0           ['conv2d_1[0][0]']               
 oling2D)                                                                                         
                                                                                                  
 conv2d_2 (Conv2D)              (None, 34, 34, 16)   4624        ['average_pooling2d_1[0][0]']    
                                                                                                  
 average_pooling2d_2 (AveragePo  (None, 17, 17, 16)  0           ['conv2d_2[0][0]']               
 oling2D)                                                                                         
                                                                                                  
 flatten (Flatten)              (None, 4624)         0           ['average_pooling2d_2[0][0]']    
                                                                                                  
 dense (Dense)                  (None, 128)          592000      ['flatten[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 225)          29025       ['dense[0][0]']                  
                                                                                                  
 dropout (Dropout)              (None, 225)          0           ['dense_1[0][0]']                
                                                                                                  
 output_1 (Dense)               (None, 5)            1130        ['dropout[0][0]']                
                                                                                                  
 output_2 (Dense)               (None, 5)            645         ['dense[0][0]']                  
                                                                                                  
==================================================================================================
Total params: 647,104
Trainable params: 647,104
Non-trainable params: 0
__________________________________________________________________________________________________
None
Epoch 1/100
2022-11-30 17:23:21.659480: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100
2022-11-30 17:23:22.710699: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2022-11-30 17:23:22.713777: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f40feb129e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-11-30 17:23:22.713790: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA RTX A5000, Compute Capability 8.6
2022-11-30 17:23:22.713794: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): NVIDIA RTX A5000, Compute Capability 8.6
2022-11-30 17:23:22.713800: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (2): NVIDIA RTX A5000, Compute Capability 8.6
2022-11-30 17:23:22.713805: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (3): NVIDIA RTX A5000, Compute Capability 8.6
2022-11-30 17:23:22.717260: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-11-30 17:23:22.811110: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
49/49 [==============================] - 5s 23ms/step - loss: 2.4000 - output_1_loss: 1.9832 - output_2_loss: 0.4168 - val_loss: 1.0916 - val_output_1_loss: 0.8755 - val_output_2_loss: 0.2161
Epoch 2/100
49/49 [==============================] - 1s 15ms/step - loss: 0.9379 - output_1_loss: 0.7721 - output_2_loss: 0.1658 - val_loss: 0.7391 - val_output_1_loss: 0.5884 - val_output_2_loss: 0.1507
Epoch 3/100
49/49 [==============================] - 1s 15ms/step - loss: 0.7936 - output_1_loss: 0.6610 - output_2_loss: 0.1326 - val_loss: 0.6410 - val_output_1_loss: 0.5166 - val_output_2_loss: 0.1244
Epoch 4/100
49/49 [==============================] - 1s 15ms/step - loss: 0.6755 - output_1_loss: 0.5700 - output_2_loss: 0.1055 - val_loss: 0.5690 - val_output_1_loss: 0.4671 - val_output_2_loss: 0.1019
Epoch 5/100
49/49 [==============================] - 1s 15ms/step - loss: 0.6025 - output_1_loss: 0.5155 - output_2_loss: 0.0870 - val_loss: 0.5025 - val_output_1_loss: 0.4140 - val_output_2_loss: 0.0885
Epoch 6/100
49/49 [==============================] - 1s 15ms/step - loss: 0.5383 - output_1_loss: 0.4690 - output_2_loss: 0.0693 - val_loss: 0.4858 - val_output_1_loss: 0.4065 - val_output_2_loss: 0.0793
Epoch 7/100
49/49 [==============================] - 1s 15ms/step - loss: 0.5104 - output_1_loss: 0.4512 - output_2_loss: 0.0592 - val_loss: 0.4153 - val_output_1_loss: 0.3483 - val_output_2_loss: 0.0670
Epoch 8/100
49/49 [==============================] - 1s 15ms/step - loss: 0.4709 - output_1_loss: 0.4196 - output_2_loss: 0.0513 - val_loss: 0.4060 - val_output_1_loss: 0.3400 - val_output_2_loss: 0.0660
Epoch 9/100
49/49 [==============================] - 1s 15ms/step - loss: 0.4314 - output_1_loss: 0.3877 - output_2_loss: 0.0436 - val_loss: 0.4037 - val_output_1_loss: 0.3439 - val_output_2_loss: 0.0597
Epoch 10/100
49/49 [==============================] - 1s 15ms/step - loss: 0.4165 - output_1_loss: 0.3792 - output_2_loss: 0.0373 - val_loss: 0.3936 - val_output_1_loss: 0.3356 - val_output_2_loss: 0.0579
Epoch 11/100
49/49 [==============================] - 1s 15ms/step - loss: 0.3941 - output_1_loss: 0.3603 - output_2_loss: 0.0338 - val_loss: 0.3609 - val_output_1_loss: 0.3088 - val_output_2_loss: 0.0520
Epoch 12/100
49/49 [==============================] - 1s 15ms/step - loss: 0.3776 - output_1_loss: 0.3474 - output_2_loss: 0.0303 - val_loss: 0.4082 - val_output_1_loss: 0.3572 - val_output_2_loss: 0.0511
Epoch 13/100
49/49 [==============================] - 1s 15ms/step - loss: 0.3815 - output_1_loss: 0.3539 - output_2_loss: 0.0276 - val_loss: 0.3432 - val_output_1_loss: 0.2934 - val_output_2_loss: 0.0498
Epoch 14/100
49/49 [==============================] - 1s 15ms/step - loss: 0.3534 - output_1_loss: 0.3295 - output_2_loss: 0.0239 - val_loss: 0.3195 - val_output_1_loss: 0.2746 - val_output_2_loss: 0.0449
Epoch 15/100
49/49 [==============================] - 1s 15ms/step - loss: 0.3400 - output_1_loss: 0.3188 - output_2_loss: 0.0212 - val_loss: 0.3096 - val_output_1_loss: 0.2674 - val_output_2_loss: 0.0422
Epoch 16/100
49/49 [==============================] - 1s 15ms/step - loss: 0.3230 - output_1_loss: 0.3037 - output_2_loss: 0.0193 - val_loss: 0.3285 - val_output_1_loss: 0.2853 - val_output_2_loss: 0.0432
Epoch 17/100
49/49 [==============================] - 1s 15ms/step - loss: 0.3259 - output_1_loss: 0.3081 - output_2_loss: 0.0178 - val_loss: 0.3038 - val_output_1_loss: 0.2635 - val_output_2_loss: 0.0403
Epoch 18/100
49/49 [==============================] - 1s 15ms/step - loss: 0.3114 - output_1_loss: 0.2954 - output_2_loss: 0.0160 - val_loss: 0.3108 - val_output_1_loss: 0.2706 - val_output_2_loss: 0.0402
Epoch 19/100
49/49 [==============================] - 1s 15ms/step - loss: 0.3008 - output_1_loss: 0.2859 - output_2_loss: 0.0149 - val_loss: 0.2876 - val_output_1_loss: 0.2505 - val_output_2_loss: 0.0371
Epoch 20/100
49/49 [==============================] - 1s 15ms/step - loss: 0.3001 - output_1_loss: 0.2863 - output_2_loss: 0.0139 - val_loss: 0.2912 - val_output_1_loss: 0.2539 - val_output_2_loss: 0.0373
Epoch 21/100
49/49 [==============================] - 1s 15ms/step - loss: 0.2986 - output_1_loss: 0.2861 - output_2_loss: 0.0125 - val_loss: 0.3205 - val_output_1_loss: 0.2844 - val_output_2_loss: 0.0361
Epoch 22/100
49/49 [==============================] - 1s 15ms/step - loss: 0.2885 - output_1_loss: 0.2770 - output_2_loss: 0.0115 - val_loss: 0.2937 - val_output_1_loss: 0.2566 - val_output_2_loss: 0.0371
Epoch 23/100
49/49 [==============================] - 1s 15ms/step - loss: 0.2885 - output_1_loss: 0.2776 - output_2_loss: 0.0109 - val_loss: 0.2784 - val_output_1_loss: 0.2431 - val_output_2_loss: 0.0353
Epoch 24/100
49/49 [==============================] - 1s 15ms/step - loss: 0.2864 - output_1_loss: 0.2759 - output_2_loss: 0.0105 - val_loss: 0.2795 - val_output_1_loss: 0.2447 - val_output_2_loss: 0.0348
Epoch 25/100
49/49 [==============================] - 1s 15ms/step - loss: 0.2746 - output_1_loss: 0.2652 - output_2_loss: 0.0094 - val_loss: 0.2982 - val_output_1_loss: 0.2638 - val_output_2_loss: 0.0344
Epoch 26/100
49/49 [==============================] - 1s 15ms/step - loss: 0.2639 - output_1_loss: 0.2556 - output_2_loss: 0.0083 - val_loss: 0.2827 - val_output_1_loss: 0.2469 - val_output_2_loss: 0.0358
Epoch 27/100
49/49 [==============================] - 1s 15ms/step - loss: 0.2670 - output_1_loss: 0.2586 - output_2_loss: 0.0084 - val_loss: 0.2845 - val_output_1_loss: 0.2497 - val_output_2_loss: 0.0348
Epoch 28/100
49/49 [==============================] - 1s 15ms/step - loss: 0.2574 - output_1_loss: 0.2502 - output_2_loss: 0.0073 - val_loss: 0.2673 - val_output_1_loss: 0.2340 - val_output_2_loss: 0.0333
Epoch 29/100
49/49 [==============================] - 1s 15ms/step - loss: 0.2527 - output_1_loss: 0.2459 - output_2_loss: 0.0068 - val_loss: 0.2618 - val_output_1_loss: 0.2284 - val_output_2_loss: 0.0334
Epoch 30/100
49/49 [==============================] - 1s 15ms/step - loss: 0.2508 - output_1_loss: 0.2442 - output_2_loss: 0.0066 - val_loss: 0.2636 - val_output_1_loss: 0.2310 - val_output_2_loss: 0.0327
Epoch 31/100
49/49 [==============================] - 1s 15ms/step - loss: 0.2470 - output_1_loss: 0.2404 - output_2_loss: 0.0066 - val_loss: 0.2701 - val_output_1_loss: 0.2384 - val_output_2_loss: 0.0318
Epoch 32/100
49/49 [==============================] - 1s 15ms/step - loss: 0.2510 - output_1_loss: 0.2445 - output_2_loss: 0.0064 - val_loss: 0.2772 - val_output_1_loss: 0.2393 - val_output_2_loss: 0.0380
Epoch 33/100
49/49 [==============================] - 1s 15ms/step - loss: 0.2434 - output_1_loss: 0.2378 - output_2_loss: 0.0056 - val_loss: 0.2635 - val_output_1_loss: 0.2290 - val_output_2_loss: 0.0345
Epoch 34/100
49/49 [==============================] - 1s 15ms/step - loss: 0.2394 - output_1_loss: 0.2344 - output_2_loss: 0.0050 - val_loss: 0.2578 - val_output_1_loss: 0.2270 - val_output_2_loss: 0.0309
Epoch 35/100
49/49 [==============================] - 1s 15ms/step - loss: 0.2448 - output_1_loss: 0.2397 - output_2_loss: 0.0050 - val_loss: 0.2566 - val_output_1_loss: 0.2231 - val_output_2_loss: 0.0335
Epoch 36/100
49/49 [==============================] - 1s 15ms/step - loss: 0.2398 - output_1_loss: 0.2351 - output_2_loss: 0.0047 - val_loss: 0.2783 - val_output_1_loss: 0.2454 - val_output_2_loss: 0.0329
Epoch 37/100
49/49 [==============================] - 1s 15ms/step - loss: 0.2316 - output_1_loss: 0.2273 - output_2_loss: 0.0043 - val_loss: 0.2600 - val_output_1_loss: 0.2290 - val_output_2_loss: 0.0310
Epoch 38/100
49/49 [==============================] - 1s 15ms/step - loss: 0.2260 - output_1_loss: 0.2221 - output_2_loss: 0.0039 - val_loss: 0.2471 - val_output_1_loss: 0.2183 - val_output_2_loss: 0.0288
Epoch 39/100
49/49 [==============================] - 1s 15ms/step - loss: 0.2311 - output_1_loss: 0.2270 - output_2_loss: 0.0041 - val_loss: 0.2493 - val_output_1_loss: 0.2181 - val_output_2_loss: 0.0312
Epoch 40/100
49/49 [==============================] - 1s 15ms/step - loss: 0.2235 - output_1_loss: 0.2198 - output_2_loss: 0.0037 - val_loss: 0.2690 - val_output_1_loss: 0.2381 - val_output_2_loss: 0.0309
Epoch 41/100
49/49 [==============================] - 1s 15ms/step - loss: 0.2335 - output_1_loss: 0.2298 - output_2_loss: 0.0036 - val_loss: 0.2431 - val_output_1_loss: 0.2120 - val_output_2_loss: 0.0312
Epoch 42/100
49/49 [==============================] - 1s 15ms/step - loss: 0.2203 - output_1_loss: 0.2168 - output_2_loss: 0.0034 - val_loss: 0.2538 - val_output_1_loss: 0.2190 - val_output_2_loss: 0.0348
Epoch 43/100
49/49 [==============================] - 1s 15ms/step - loss: 0.2175 - output_1_loss: 0.2143 - output_2_loss: 0.0032 - val_loss: 0.2365 - val_output_1_loss: 0.2060 - val_output_2_loss: 0.0305
Epoch 44/100
49/49 [==============================] - 1s 15ms/step - loss: 0.2166 - output_1_loss: 0.2133 - output_2_loss: 0.0033 - val_loss: 0.2431 - val_output_1_loss: 0.2078 - val_output_2_loss: 0.0353
Epoch 45/100
49/49 [==============================] - 1s 15ms/step - loss: 0.2141 - output_1_loss: 0.2111 - output_2_loss: 0.0030 - val_loss: 0.2489 - val_output_1_loss: 0.2164 - val_output_2_loss: 0.0325
Epoch 46/100
49/49 [==============================] - 1s 15ms/step - loss: 0.2143 - output_1_loss: 0.2113 - output_2_loss: 0.0030 - val_loss: 0.2393 - val_output_1_loss: 0.2042 - val_output_2_loss: 0.0351
Epoch 47/100
49/49 [==============================] - 1s 15ms/step - loss: 0.2128 - output_1_loss: 0.2099 - output_2_loss: 0.0029 - val_loss: 0.2360 - val_output_1_loss: 0.2063 - val_output_2_loss: 0.0297
Epoch 48/100
49/49 [==============================] - 1s 15ms/step - loss: 0.2177 - output_1_loss: 0.2147 - output_2_loss: 0.0030 - val_loss: 0.2378 - val_output_1_loss: 0.2055 - val_output_2_loss: 0.0323
Epoch 49/100
49/49 [==============================] - 1s 15ms/step - loss: 0.2075 - output_1_loss: 0.2048 - output_2_loss: 0.0028 - val_loss: 0.2200 - val_output_1_loss: 0.1903 - val_output_2_loss: 0.0297
Epoch 50/100
49/49 [==============================] - 1s 15ms/step - loss: 0.2096 - output_1_loss: 0.2069 - output_2_loss: 0.0027 - val_loss: 0.2456 - val_output_1_loss: 0.2145 - val_output_2_loss: 0.0312
Epoch 51/100
49/49 [==============================] - 1s 15ms/step - loss: 0.2097 - output_1_loss: 0.2073 - output_2_loss: 0.0024 - val_loss: 0.2411 - val_output_1_loss: 0.2066 - val_output_2_loss: 0.0346
Epoch 52/100
49/49 [==============================] - 1s 15ms/step - loss: 0.2100 - output_1_loss: 0.2077 - output_2_loss: 0.0023 - val_loss: 0.2249 - val_output_1_loss: 0.1920 - val_output_2_loss: 0.0329
Epoch 53/100
49/49 [==============================] - 1s 15ms/step - loss: 0.2075 - output_1_loss: 0.2053 - output_2_loss: 0.0022 - val_loss: 0.2265 - val_output_1_loss: 0.1939 - val_output_2_loss: 0.0326
Epoch 54/100
49/49 [==============================] - 1s 15ms/step - loss: 0.2087 - output_1_loss: 0.2065 - output_2_loss: 0.0022 - val_loss: 0.2250 - val_output_1_loss: 0.1948 - val_output_2_loss: 0.0302
Epoch 55/100
49/49 [==============================] - 1s 15ms/step - loss: 0.2002 - output_1_loss: 0.1982 - output_2_loss: 0.0020 - val_loss: 0.2215 - val_output_1_loss: 0.1899 - val_output_2_loss: 0.0316
Epoch 56/100
49/49 [==============================] - 1s 15ms/step - loss: 0.1993 - output_1_loss: 0.1972 - output_2_loss: 0.0021 - val_loss: 0.2208 - val_output_1_loss: 0.1896 - val_output_2_loss: 0.0313
Epoch 57/100
49/49 [==============================] - 1s 15ms/step - loss: 0.2014 - output_1_loss: 0.1994 - output_2_loss: 0.0021 - val_loss: 0.2192 - val_output_1_loss: 0.1872 - val_output_2_loss: 0.0320
Epoch 58/100
49/49 [==============================] - 1s 15ms/step - loss: 0.1949 - output_1_loss: 0.1930 - output_2_loss: 0.0019 - val_loss: 0.2462 - val_output_1_loss: 0.2175 - val_output_2_loss: 0.0287
Epoch 59/100
49/49 [==============================] - 1s 15ms/step - loss: 0.1951 - output_1_loss: 0.1931 - output_2_loss: 0.0020 - val_loss: 0.2273 - val_output_1_loss: 0.1969 - val_output_2_loss: 0.0305
Epoch 60/100
49/49 [==============================] - 1s 15ms/step - loss: 0.2047 - output_1_loss: 0.2029 - output_2_loss: 0.0018 - val_loss: 0.2839 - val_output_1_loss: 0.2524 - val_output_2_loss: 0.0315
Epoch 61/100
49/49 [==============================] - 1s 15ms/step - loss: 0.1921 - output_1_loss: 0.1902 - output_2_loss: 0.0019 - val_loss: 0.2259 - val_output_1_loss: 0.1944 - val_output_2_loss: 0.0315
Epoch 62/100
49/49 [==============================] - 1s 15ms/step - loss: 0.1951 - output_1_loss: 0.1933 - output_2_loss: 0.0018 - val_loss: 0.2171 - val_output_1_loss: 0.1853 - val_output_2_loss: 0.0318
Epoch 63/100
49/49 [==============================] - 1s 15ms/step - loss: 0.1908 - output_1_loss: 0.1891 - output_2_loss: 0.0017 - val_loss: 0.2232 - val_output_1_loss: 0.1933 - val_output_2_loss: 0.0299
Epoch 64/100
49/49 [==============================] - 1s 15ms/step - loss: 0.1868 - output_1_loss: 0.1852 - output_2_loss: 0.0016 - val_loss: 0.2188 - val_output_1_loss: 0.1868 - val_output_2_loss: 0.0320
Epoch 65/100
49/49 [==============================] - 1s 15ms/step - loss: 0.1908 - output_1_loss: 0.1892 - output_2_loss: 0.0016 - val_loss: 0.2291 - val_output_1_loss: 0.1982 - val_output_2_loss: 0.0309
Epoch 66/100
49/49 [==============================] - 1s 15ms/step - loss: 0.1856 - output_1_loss: 0.1840 - output_2_loss: 0.0016 - val_loss: 0.2178 - val_output_1_loss: 0.1860 - val_output_2_loss: 0.0318
Epoch 67/100
49/49 [==============================] - 1s 15ms/step - loss: 0.1870 - output_1_loss: 0.1855 - output_2_loss: 0.0016 - val_loss: 0.2201 - val_output_1_loss: 0.1891 - val_output_2_loss: 0.0310
Epoch 68/100
49/49 [==============================] - 1s 15ms/step - loss: 0.1934 - output_1_loss: 0.1918 - output_2_loss: 0.0016 - val_loss: 0.2317 - val_output_1_loss: 0.1965 - val_output_2_loss: 0.0351
Epoch 69/100
49/49 [==============================] - 1s 15ms/step - loss: 0.1881 - output_1_loss: 0.1867 - output_2_loss: 0.0015 - val_loss: 0.2113 - val_output_1_loss: 0.1791 - val_output_2_loss: 0.0322
Epoch 70/100
49/49 [==============================] - 1s 15ms/step - loss: 0.1891 - output_1_loss: 0.1876 - output_2_loss: 0.0015 - val_loss: 0.2248 - val_output_1_loss: 0.1895 - val_output_2_loss: 0.0353
Epoch 71/100
49/49 [==============================] - 1s 15ms/step - loss: 0.1856 - output_1_loss: 0.1842 - output_2_loss: 0.0014 - val_loss: 0.2160 - val_output_1_loss: 0.1814 - val_output_2_loss: 0.0345
Epoch 72/100
49/49 [==============================] - 1s 15ms/step - loss: 0.1808 - output_1_loss: 0.1793 - output_2_loss: 0.0015 - val_loss: 0.2076 - val_output_1_loss: 0.1777 - val_output_2_loss: 0.0299
Epoch 73/100
49/49 [==============================] - 1s 15ms/step - loss: 0.1834 - output_1_loss: 0.1820 - output_2_loss: 0.0014 - val_loss: 0.2465 - val_output_1_loss: 0.2160 - val_output_2_loss: 0.0306
Epoch 74/100
49/49 [==============================] - 1s 15ms/step - loss: 0.1851 - output_1_loss: 0.1836 - output_2_loss: 0.0015 - val_loss: 0.2244 - val_output_1_loss: 0.1875 - val_output_2_loss: 0.0369
Epoch 75/100
49/49 [==============================] - 1s 15ms/step - loss: 0.1833 - output_1_loss: 0.1818 - output_2_loss: 0.0014 - val_loss: 0.2084 - val_output_1_loss: 0.1765 - val_output_2_loss: 0.0318
Epoch 76/100
49/49 [==============================] - 1s 15ms/step - loss: 0.1795 - output_1_loss: 0.1782 - output_2_loss: 0.0013 - val_loss: 0.2132 - val_output_1_loss: 0.1805 - val_output_2_loss: 0.0326
Epoch 77/100
49/49 [==============================] - 1s 15ms/step - loss: 0.1800 - output_1_loss: 0.1787 - output_2_loss: 0.0013 - val_loss: 0.2034 - val_output_1_loss: 0.1716 - val_output_2_loss: 0.0319
Epoch 78/100
49/49 [==============================] - 1s 15ms/step - loss: 0.1758 - output_1_loss: 0.1745 - output_2_loss: 0.0013 - val_loss: 0.2125 - val_output_1_loss: 0.1804 - val_output_2_loss: 0.0321
Epoch 79/100
49/49 [==============================] - 1s 15ms/step - loss: 0.1830 - output_1_loss: 0.1817 - output_2_loss: 0.0012 - val_loss: 0.2212 - val_output_1_loss: 0.1884 - val_output_2_loss: 0.0328
Epoch 80/100
49/49 [==============================] - 1s 15ms/step - loss: 0.1776 - output_1_loss: 0.1764 - output_2_loss: 0.0012 - val_loss: 0.2121 - val_output_1_loss: 0.1782 - val_output_2_loss: 0.0339
Epoch 81/100
49/49 [==============================] - 1s 15ms/step - loss: 0.1760 - output_1_loss: 0.1749 - output_2_loss: 0.0012 - val_loss: 0.2409 - val_output_1_loss: 0.2095 - val_output_2_loss: 0.0314
Epoch 82/100
49/49 [==============================] - 1s 15ms/step - loss: 0.1784 - output_1_loss: 0.1773 - output_2_loss: 0.0012 - val_loss: 0.2042 - val_output_1_loss: 0.1719 - val_output_2_loss: 0.0323
Epoch 83/100
49/49 [==============================] - 1s 15ms/step - loss: 0.1765 - output_1_loss: 0.1754 - output_2_loss: 0.0011 - val_loss: 0.2159 - val_output_1_loss: 0.1828 - val_output_2_loss: 0.0331
Epoch 84/100
49/49 [==============================] - 1s 15ms/step - loss: 0.1739 - output_1_loss: 0.1727 - output_2_loss: 0.0012 - val_loss: 0.2065 - val_output_1_loss: 0.1728 - val_output_2_loss: 0.0336
Epoch 85/100
49/49 [==============================] - 1s 15ms/step - loss: 0.1733 - output_1_loss: 0.1722 - output_2_loss: 0.0011 - val_loss: 0.2004 - val_output_1_loss: 0.1702 - val_output_2_loss: 0.0302
Epoch 86/100
49/49 [==============================] - 1s 15ms/step - loss: 0.1717 - output_1_loss: 0.1706 - output_2_loss: 0.0011 - val_loss: 0.2085 - val_output_1_loss: 0.1759 - val_output_2_loss: 0.0327
Epoch 87/100
49/49 [==============================] - 1s 15ms/step - loss: 0.1717 - output_1_loss: 0.1706 - output_2_loss: 0.0010 - val_loss: 0.2126 - val_output_1_loss: 0.1812 - val_output_2_loss: 0.0313
Epoch 88/100
49/49 [==============================] - 1s 15ms/step - loss: 0.1684 - output_1_loss: 0.1673 - output_2_loss: 0.0011 - val_loss: 0.2303 - val_output_1_loss: 0.2003 - val_output_2_loss: 0.0300
Epoch 89/100
49/49 [==============================] - 1s 15ms/step - loss: 0.1711 - output_1_loss: 0.1701 - output_2_loss: 0.0011 - val_loss: 0.2041 - val_output_1_loss: 0.1735 - val_output_2_loss: 0.0305
Epoch 90/100
49/49 [==============================] - 1s 15ms/step - loss: 0.1692 - output_1_loss: 0.1681 - output_2_loss: 0.0011 - val_loss: 0.2050 - val_output_1_loss: 0.1733 - val_output_2_loss: 0.0316
Epoch 91/100
49/49 [==============================] - 1s 15ms/step - loss: 0.1687 - output_1_loss: 0.1677 - output_2_loss: 9.9292e-04 - val_loss: 0.2276 - val_output_1_loss: 0.1951 - val_output_2_loss: 0.0325
Epoch 92/100
49/49 [==============================] - 1s 15ms/step - loss: 0.1707 - output_1_loss: 0.1697 - output_2_loss: 0.0010 - val_loss: 0.2133 - val_output_1_loss: 0.1809 - val_output_2_loss: 0.0324
Epoch 93/100
49/49 [==============================] - 1s 15ms/step - loss: 0.1657 - output_1_loss: 0.1647 - output_2_loss: 9.8417e-04 - val_loss: 0.2055 - val_output_1_loss: 0.1722 - val_output_2_loss: 0.0334
Epoch 94/100
49/49 [==============================] - 1s 15ms/step - loss: 0.1694 - output_1_loss: 0.1685 - output_2_loss: 9.2283e-04 - val_loss: 0.2067 - val_output_1_loss: 0.1747 - val_output_2_loss: 0.0321
Epoch 95/100
49/49 [==============================] - 1s 15ms/step - loss: 0.1667 - output_1_loss: 0.1657 - output_2_loss: 0.0011 - val_loss: 0.2185 - val_output_1_loss: 0.1900 - val_output_2_loss: 0.0285
Epoch 96/100
49/49 [==============================] - 1s 15ms/step - loss: 0.1665 - output_1_loss: 0.1655 - output_2_loss: 9.4347e-04 - val_loss: 0.2031 - val_output_1_loss: 0.1712 - val_output_2_loss: 0.0319
Epoch 97/100
49/49 [==============================] - 1s 15ms/step - loss: 0.1640 - output_1_loss: 0.1631 - output_2_loss: 9.4172e-04 - val_loss: 0.2029 - val_output_1_loss: 0.1707 - val_output_2_loss: 0.0322
Epoch 98/100
49/49 [==============================] - 1s 15ms/step - loss: 0.1648 - output_1_loss: 0.1639 - output_2_loss: 8.7338e-04 - val_loss: 0.1963 - val_output_1_loss: 0.1628 - val_output_2_loss: 0.0335
Epoch 99/100
49/49 [==============================] - 1s 15ms/step - loss: 0.1616 - output_1_loss: 0.1606 - output_2_loss: 9.6992e-04 - val_loss: 0.2336 - val_output_1_loss: 0.2015 - val_output_2_loss: 0.0320
Epoch 100/100
49/49 [==============================] - 1s 15ms/step - loss: 0.1619 - output_1_loss: 0.1610 - output_2_loss: 9.2956e-04 - val_loss: 0.2208 - val_output_1_loss: 0.1874 - val_output_2_loss: 0.0333
Keras weights file (<HDF5 file "variables.h5" (mode r+)>) saving:
...layers
......average_pooling2d
.........vars
......average_pooling2d_1
.........vars
......average_pooling2d_2
.........vars
......conv2d
.........vars
............0
............1
......conv2d_1
.........vars
............0
............1
......conv2d_2
.........vars
............0
............1
......dense
.........vars
............0
............1
......dense_1
.........vars
............0
............1
......dense_2
.........vars
............0
............1
......dense_3
.........vars
............0
............1
......dropout
.........vars
......flatten
.........vars
......input_layer
.........vars
...metrics
......mean
.........vars
............0
............1
......mean_1
.........vars
............0
............1
......mean_2
.........vars
............0
............1
...optimizer
......vars
.........0
.........1
.........10
.........11
.........12
.........13
.........14
.........15
.........16
.........17
.........18
.........19
.........2
.........20
.........21
.........22
.........23
.........24
.........25
.........26
.........27
.........28
.........3
.........4
.........5
.........6
.........7
.........8
.........9
...vars
Keras model archive saving:
File Name                                             Modified             Size
variables.h5                                   2022-11-30 17:24:37      7819476
config.json                                    2022-11-30 17:24:37         5811
metadata.json                                  2022-11-30 17:24:37           64
33/33 [==============================] - 0s 4ms/step
accuracy_score  > 0.965
mean_absolute_error 0.18541658454836737 mean_squared_error 0.13273119094011204

