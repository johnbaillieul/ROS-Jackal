Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 300, 300, 2  0           []                               
                                )]                                                                
                                                                                                  
 conv2d (Conv2D)                (None, 298, 298, 64  1216        ['input_1[0][0]']                
                                )                                                                 
                                                                                                  
 average_pooling2d (AveragePool  (None, 149, 149, 64  0          ['conv2d[0][0]']                 
 ing2D)                         )                                                                 
                                                                                                  
 conv2d_1 (Conv2D)              (None, 147, 147, 32  18464       ['average_pooling2d[0][0]']      
                                )                                                                 
                                                                                                  
 average_pooling2d_1 (AveragePo  (None, 73, 73, 32)  0           ['conv2d_1[0][0]']               
 oling2D)                                                                                         
                                                                                                  
 conv2d_2 (Conv2D)              (None, 71, 71, 16)   4624        ['average_pooling2d_1[0][0]']    
                                                                                                  
 average_pooling2d_2 (AveragePo  (None, 35, 35, 16)  0           ['conv2d_2[0][0]']               
 oling2D)                                                                                         
                                                                                                  
 flatten (Flatten)              (None, 19600)        0           ['average_pooling2d_2[0][0]']    
                                                                                                  
 dense (Dense)                  (None, 128)          2508928     ['flatten[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 225)          29025       ['dense[0][0]']                  
                                                                                                  
 dropout (Dropout)              (None, 225)          0           ['dense_1[0][0]']                
                                                                                                  
 output_1 (Dense)               (None, 5)            1130        ['dropout[0][0]']                
                                                                                                  
 output_2 (Dense)               (None, 5)            645         ['dense[0][0]']                  
                                                                                                  
==================================================================================================
Total params: 2,564,032
Trainable params: 2,564,032
Non-trainable params: 0
__________________________________________________________________________________________________
None
Epoch 1/100
2022-11-30 17:30:45.514788: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100
2022-11-30 17:30:46.842647: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2022-11-30 17:30:46.846527: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x3413ac70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-11-30 17:30:46.846560: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA RTX A5000, Compute Capability 8.6
2022-11-30 17:30:46.846569: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): NVIDIA RTX A5000, Compute Capability 8.6
2022-11-30 17:30:46.846579: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (2): NVIDIA RTX A5000, Compute Capability 8.6
2022-11-30 17:30:46.846588: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (3): NVIDIA RTX A5000, Compute Capability 8.6
2022-11-30 17:30:46.852865: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-11-30 17:30:46.948521: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
49/49 [==============================] - 8s 71ms/step - loss: 2.3511 - output_1_loss: 1.9408 - output_2_loss: 0.4103 - val_loss: 0.7540 - val_output_1_loss: 0.6116 - val_output_2_loss: 0.1425
Epoch 2/100
49/49 [==============================] - 3s 52ms/step - loss: 0.8283 - output_1_loss: 0.7107 - output_2_loss: 0.1175 - val_loss: 0.7645 - val_output_1_loss: 0.6725 - val_output_2_loss: 0.0920
Epoch 3/100
49/49 [==============================] - 3s 52ms/step - loss: 0.6787 - output_1_loss: 0.5990 - output_2_loss: 0.0797 - val_loss: 0.6149 - val_output_1_loss: 0.5191 - val_output_2_loss: 0.0957
Epoch 4/100
49/49 [==============================] - 3s 52ms/step - loss: 0.5762 - output_1_loss: 0.5173 - output_2_loss: 0.0589 - val_loss: 0.4772 - val_output_1_loss: 0.4111 - val_output_2_loss: 0.0661
Epoch 5/100
49/49 [==============================] - 3s 52ms/step - loss: 0.5156 - output_1_loss: 0.4704 - output_2_loss: 0.0452 - val_loss: 0.4810 - val_output_1_loss: 0.4188 - val_output_2_loss: 0.0622
Epoch 6/100
49/49 [==============================] - 3s 52ms/step - loss: 0.4697 - output_1_loss: 0.4322 - output_2_loss: 0.0376 - val_loss: 0.3971 - val_output_1_loss: 0.3431 - val_output_2_loss: 0.0540
Epoch 7/100
49/49 [==============================] - 3s 53ms/step - loss: 0.4437 - output_1_loss: 0.4120 - output_2_loss: 0.0316 - val_loss: 0.3893 - val_output_1_loss: 0.3393 - val_output_2_loss: 0.0500
Epoch 8/100
49/49 [==============================] - 3s 53ms/step - loss: 0.4169 - output_1_loss: 0.3893 - output_2_loss: 0.0276 - val_loss: 0.3500 - val_output_1_loss: 0.3045 - val_output_2_loss: 0.0455
Epoch 9/100
49/49 [==============================] - 3s 52ms/step - loss: 0.3911 - output_1_loss: 0.3685 - output_2_loss: 0.0226 - val_loss: 0.3748 - val_output_1_loss: 0.3302 - val_output_2_loss: 0.0446
Epoch 10/100
49/49 [==============================] - 3s 53ms/step - loss: 0.3755 - output_1_loss: 0.3559 - output_2_loss: 0.0196 - val_loss: 0.3425 - val_output_1_loss: 0.3008 - val_output_2_loss: 0.0417
Epoch 11/100
49/49 [==============================] - 3s 53ms/step - loss: 0.3686 - output_1_loss: 0.3504 - output_2_loss: 0.0182 - val_loss: 0.3360 - val_output_1_loss: 0.2977 - val_output_2_loss: 0.0384
Epoch 12/100
49/49 [==============================] - 3s 53ms/step - loss: 0.3502 - output_1_loss: 0.3349 - output_2_loss: 0.0154 - val_loss: 0.3420 - val_output_1_loss: 0.3052 - val_output_2_loss: 0.0368
Epoch 13/100
49/49 [==============================] - 3s 53ms/step - loss: 0.3466 - output_1_loss: 0.3325 - output_2_loss: 0.0141 - val_loss: 0.3237 - val_output_1_loss: 0.2863 - val_output_2_loss: 0.0374
Epoch 14/100
49/49 [==============================] - 3s 53ms/step - loss: 0.3284 - output_1_loss: 0.3154 - output_2_loss: 0.0129 - val_loss: 0.3071 - val_output_1_loss: 0.2693 - val_output_2_loss: 0.0378
Epoch 15/100
49/49 [==============================] - 3s 53ms/step - loss: 0.3280 - output_1_loss: 0.3164 - output_2_loss: 0.0115 - val_loss: 0.3348 - val_output_1_loss: 0.2975 - val_output_2_loss: 0.0373
Epoch 16/100
49/49 [==============================] - 3s 53ms/step - loss: 0.3367 - output_1_loss: 0.3252 - output_2_loss: 0.0115 - val_loss: 0.3039 - val_output_1_loss: 0.2686 - val_output_2_loss: 0.0353
Epoch 17/100
49/49 [==============================] - 3s 53ms/step - loss: 0.3109 - output_1_loss: 0.3015 - output_2_loss: 0.0094 - val_loss: 0.3068 - val_output_1_loss: 0.2712 - val_output_2_loss: 0.0356
Epoch 18/100
49/49 [==============================] - 3s 53ms/step - loss: 0.3011 - output_1_loss: 0.2925 - output_2_loss: 0.0086 - val_loss: 0.2987 - val_output_1_loss: 0.2649 - val_output_2_loss: 0.0338
Epoch 19/100
49/49 [==============================] - 3s 53ms/step - loss: 0.2957 - output_1_loss: 0.2875 - output_2_loss: 0.0082 - val_loss: 0.2821 - val_output_1_loss: 0.2474 - val_output_2_loss: 0.0347
Epoch 20/100
49/49 [==============================] - 3s 53ms/step - loss: 0.2822 - output_1_loss: 0.2748 - output_2_loss: 0.0073 - val_loss: 0.2780 - val_output_1_loss: 0.2446 - val_output_2_loss: 0.0334
Epoch 21/100
49/49 [==============================] - 3s 53ms/step - loss: 0.2795 - output_1_loss: 0.2721 - output_2_loss: 0.0074 - val_loss: 0.2940 - val_output_1_loss: 0.2602 - val_output_2_loss: 0.0338
Epoch 22/100
49/49 [==============================] - 3s 53ms/step - loss: 0.2824 - output_1_loss: 0.2758 - output_2_loss: 0.0066 - val_loss: 0.2984 - val_output_1_loss: 0.2641 - val_output_2_loss: 0.0344
Epoch 23/100
49/49 [==============================] - 3s 53ms/step - loss: 0.2722 - output_1_loss: 0.2656 - output_2_loss: 0.0065 - val_loss: 0.2796 - val_output_1_loss: 0.2456 - val_output_2_loss: 0.0340
Epoch 24/100
49/49 [==============================] - 3s 53ms/step - loss: 0.2644 - output_1_loss: 0.2586 - output_2_loss: 0.0058 - val_loss: 0.2632 - val_output_1_loss: 0.2293 - val_output_2_loss: 0.0339
Epoch 25/100
49/49 [==============================] - 3s 53ms/step - loss: 0.2669 - output_1_loss: 0.2616 - output_2_loss: 0.0052 - val_loss: 0.2624 - val_output_1_loss: 0.2288 - val_output_2_loss: 0.0335
Epoch 26/100
49/49 [==============================] - 3s 53ms/step - loss: 0.2586 - output_1_loss: 0.2534 - output_2_loss: 0.0052 - val_loss: 0.2805 - val_output_1_loss: 0.2488 - val_output_2_loss: 0.0317
Epoch 27/100
49/49 [==============================] - 3s 53ms/step - loss: 0.2596 - output_1_loss: 0.2550 - output_2_loss: 0.0046 - val_loss: 0.2675 - val_output_1_loss: 0.2351 - val_output_2_loss: 0.0324
Epoch 28/100
49/49 [==============================] - 3s 53ms/step - loss: 0.2549 - output_1_loss: 0.2503 - output_2_loss: 0.0046 - val_loss: 0.2799 - val_output_1_loss: 0.2481 - val_output_2_loss: 0.0318
Epoch 29/100
49/49 [==============================] - 3s 53ms/step - loss: 0.2581 - output_1_loss: 0.2532 - output_2_loss: 0.0049 - val_loss: 0.2551 - val_output_1_loss: 0.2219 - val_output_2_loss: 0.0333
Epoch 30/100
49/49 [==============================] - 3s 53ms/step - loss: 0.2446 - output_1_loss: 0.2403 - output_2_loss: 0.0043 - val_loss: 0.2649 - val_output_1_loss: 0.2326 - val_output_2_loss: 0.0322
Epoch 31/100
49/49 [==============================] - 3s 53ms/step - loss: 0.2415 - output_1_loss: 0.2376 - output_2_loss: 0.0040 - val_loss: 0.2544 - val_output_1_loss: 0.2222 - val_output_2_loss: 0.0322
Epoch 32/100
49/49 [==============================] - 3s 53ms/step - loss: 0.2383 - output_1_loss: 0.2346 - output_2_loss: 0.0037 - val_loss: 0.2568 - val_output_1_loss: 0.2270 - val_output_2_loss: 0.0298
Epoch 33/100
49/49 [==============================] - 3s 53ms/step - loss: 0.2360 - output_1_loss: 0.2322 - output_2_loss: 0.0037 - val_loss: 0.2514 - val_output_1_loss: 0.2184 - val_output_2_loss: 0.0330
Epoch 34/100
49/49 [==============================] - 3s 53ms/step - loss: 0.2316 - output_1_loss: 0.2280 - output_2_loss: 0.0036 - val_loss: 0.2706 - val_output_1_loss: 0.2384 - val_output_2_loss: 0.0322
Epoch 35/100
49/49 [==============================] - 3s 53ms/step - loss: 0.2291 - output_1_loss: 0.2257 - output_2_loss: 0.0034 - val_loss: 0.2449 - val_output_1_loss: 0.2116 - val_output_2_loss: 0.0333
Epoch 36/100
49/49 [==============================] - 3s 53ms/step - loss: 0.2373 - output_1_loss: 0.2341 - output_2_loss: 0.0032 - val_loss: 0.2559 - val_output_1_loss: 0.2244 - val_output_2_loss: 0.0315
Epoch 37/100
49/49 [==============================] - 3s 53ms/step - loss: 0.2310 - output_1_loss: 0.2279 - output_2_loss: 0.0032 - val_loss: 0.2400 - val_output_1_loss: 0.2091 - val_output_2_loss: 0.0309
Epoch 38/100
49/49 [==============================] - 3s 53ms/step - loss: 0.2241 - output_1_loss: 0.2210 - output_2_loss: 0.0031 - val_loss: 0.2467 - val_output_1_loss: 0.2158 - val_output_2_loss: 0.0309
Epoch 39/100
49/49 [==============================] - 3s 53ms/step - loss: 0.2208 - output_1_loss: 0.2179 - output_2_loss: 0.0029 - val_loss: 0.2385 - val_output_1_loss: 0.2056 - val_output_2_loss: 0.0330
Epoch 40/100
49/49 [==============================] - 3s 53ms/step - loss: 0.2182 - output_1_loss: 0.2154 - output_2_loss: 0.0028 - val_loss: 0.2362 - val_output_1_loss: 0.2058 - val_output_2_loss: 0.0304
Epoch 41/100
49/49 [==============================] - 3s 53ms/step - loss: 0.2179 - output_1_loss: 0.2152 - output_2_loss: 0.0026 - val_loss: 0.2691 - val_output_1_loss: 0.2373 - val_output_2_loss: 0.0317
Epoch 42/100
49/49 [==============================] - 3s 53ms/step - loss: 0.2226 - output_1_loss: 0.2201 - output_2_loss: 0.0025 - val_loss: 0.2745 - val_output_1_loss: 0.2436 - val_output_2_loss: 0.0309
Epoch 43/100
49/49 [==============================] - 3s 53ms/step - loss: 0.2155 - output_1_loss: 0.2131 - output_2_loss: 0.0024 - val_loss: 0.2424 - val_output_1_loss: 0.2096 - val_output_2_loss: 0.0327
Epoch 44/100
49/49 [==============================] - 3s 53ms/step - loss: 0.2166 - output_1_loss: 0.2142 - output_2_loss: 0.0024 - val_loss: 0.2417 - val_output_1_loss: 0.2085 - val_output_2_loss: 0.0332
Epoch 45/100
49/49 [==============================] - 3s 53ms/step - loss: 0.2115 - output_1_loss: 0.2092 - output_2_loss: 0.0023 - val_loss: 0.2801 - val_output_1_loss: 0.2484 - val_output_2_loss: 0.0318
Epoch 46/100
49/49 [==============================] - 3s 53ms/step - loss: 0.2121 - output_1_loss: 0.2099 - output_2_loss: 0.0023 - val_loss: 0.2559 - val_output_1_loss: 0.2214 - val_output_2_loss: 0.0345
Epoch 47/100
49/49 [==============================] - 3s 53ms/step - loss: 0.2128 - output_1_loss: 0.2106 - output_2_loss: 0.0022 - val_loss: 0.2532 - val_output_1_loss: 0.2209 - val_output_2_loss: 0.0323
Epoch 48/100
49/49 [==============================] - 3s 53ms/step - loss: 0.2118 - output_1_loss: 0.2095 - output_2_loss: 0.0023 - val_loss: 0.2410 - val_output_1_loss: 0.2073 - val_output_2_loss: 0.0337
Epoch 49/100
49/49 [==============================] - 3s 53ms/step - loss: 0.2071 - output_1_loss: 0.2050 - output_2_loss: 0.0021 - val_loss: 0.2355 - val_output_1_loss: 0.2060 - val_output_2_loss: 0.0295
Epoch 50/100
49/49 [==============================] - 3s 53ms/step - loss: 0.2085 - output_1_loss: 0.2064 - output_2_loss: 0.0021 - val_loss: 0.2321 - val_output_1_loss: 0.2001 - val_output_2_loss: 0.0321
Epoch 51/100
49/49 [==============================] - 3s 53ms/step - loss: 0.2045 - output_1_loss: 0.2027 - output_2_loss: 0.0018 - val_loss: 0.2338 - val_output_1_loss: 0.2036 - val_output_2_loss: 0.0302
Epoch 52/100
49/49 [==============================] - 3s 53ms/step - loss: 0.2024 - output_1_loss: 0.2006 - output_2_loss: 0.0018 - val_loss: 0.2277 - val_output_1_loss: 0.1972 - val_output_2_loss: 0.0305
Epoch 53/100
49/49 [==============================] - 3s 53ms/step - loss: 0.2007 - output_1_loss: 0.1989 - output_2_loss: 0.0018 - val_loss: 0.2331 - val_output_1_loss: 0.2016 - val_output_2_loss: 0.0316
Epoch 54/100
49/49 [==============================] - 3s 53ms/step - loss: 0.2004 - output_1_loss: 0.1986 - output_2_loss: 0.0018 - val_loss: 0.2244 - val_output_1_loss: 0.1933 - val_output_2_loss: 0.0312
Epoch 55/100
49/49 [==============================] - 3s 53ms/step - loss: 0.2014 - output_1_loss: 0.1998 - output_2_loss: 0.0017 - val_loss: 0.2278 - val_output_1_loss: 0.1961 - val_output_2_loss: 0.0317
Epoch 56/100
49/49 [==============================] - 3s 53ms/step - loss: 0.1991 - output_1_loss: 0.1974 - output_2_loss: 0.0017 - val_loss: 0.2335 - val_output_1_loss: 0.2016 - val_output_2_loss: 0.0319
Epoch 57/100
49/49 [==============================] - 3s 53ms/step - loss: 0.2032 - output_1_loss: 0.2013 - output_2_loss: 0.0018 - val_loss: 0.2644 - val_output_1_loss: 0.2331 - val_output_2_loss: 0.0313
Epoch 58/100
49/49 [==============================] - 3s 53ms/step - loss: 0.2027 - output_1_loss: 0.2012 - output_2_loss: 0.0016 - val_loss: 0.2328 - val_output_1_loss: 0.2004 - val_output_2_loss: 0.0324
Epoch 59/100
49/49 [==============================] - 3s 53ms/step - loss: 0.1915 - output_1_loss: 0.1898 - output_2_loss: 0.0017 - val_loss: 0.2304 - val_output_1_loss: 0.1966 - val_output_2_loss: 0.0338
Epoch 60/100
49/49 [==============================] - 3s 53ms/step - loss: 0.1971 - output_1_loss: 0.1955 - output_2_loss: 0.0016 - val_loss: 0.2393 - val_output_1_loss: 0.2067 - val_output_2_loss: 0.0326
Epoch 61/100
49/49 [==============================] - 3s 53ms/step - loss: 0.1983 - output_1_loss: 0.1969 - output_2_loss: 0.0015 - val_loss: 0.2319 - val_output_1_loss: 0.1985 - val_output_2_loss: 0.0334
Epoch 62/100
49/49 [==============================] - 3s 53ms/step - loss: 0.1881 - output_1_loss: 0.1865 - output_2_loss: 0.0016 - val_loss: 0.2308 - val_output_1_loss: 0.1993 - val_output_2_loss: 0.0315
Epoch 63/100
49/49 [==============================] - 3s 53ms/step - loss: 0.1879 - output_1_loss: 0.1864 - output_2_loss: 0.0015 - val_loss: 0.2241 - val_output_1_loss: 0.1905 - val_output_2_loss: 0.0336
Epoch 64/100
49/49 [==============================] - 3s 53ms/step - loss: 0.1871 - output_1_loss: 0.1857 - output_2_loss: 0.0014 - val_loss: 0.2338 - val_output_1_loss: 0.2027 - val_output_2_loss: 0.0311
Epoch 65/100
49/49 [==============================] - 3s 53ms/step - loss: 0.1911 - output_1_loss: 0.1896 - output_2_loss: 0.0014 - val_loss: 0.2463 - val_output_1_loss: 0.2136 - val_output_2_loss: 0.0327
Epoch 66/100
49/49 [==============================] - 3s 53ms/step - loss: 0.1917 - output_1_loss: 0.1902 - output_2_loss: 0.0014 - val_loss: 0.2313 - val_output_1_loss: 0.1979 - val_output_2_loss: 0.0334
Epoch 67/100
49/49 [==============================] - 3s 53ms/step - loss: 0.1877 - output_1_loss: 0.1864 - output_2_loss: 0.0013 - val_loss: 0.2404 - val_output_1_loss: 0.2087 - val_output_2_loss: 0.0317
Epoch 68/100
49/49 [==============================] - 3s 53ms/step - loss: 0.1844 - output_1_loss: 0.1830 - output_2_loss: 0.0014 - val_loss: 0.2136 - val_output_1_loss: 0.1823 - val_output_2_loss: 0.0313
Epoch 69/100
49/49 [==============================] - 3s 53ms/step - loss: 0.1864 - output_1_loss: 0.1851 - output_2_loss: 0.0013 - val_loss: 0.2153 - val_output_1_loss: 0.1837 - val_output_2_loss: 0.0316
Epoch 70/100
49/49 [==============================] - 3s 53ms/step - loss: 0.1833 - output_1_loss: 0.1821 - output_2_loss: 0.0012 - val_loss: 0.2219 - val_output_1_loss: 0.1895 - val_output_2_loss: 0.0324
Epoch 71/100
49/49 [==============================] - 3s 53ms/step - loss: 0.1840 - output_1_loss: 0.1825 - output_2_loss: 0.0015 - val_loss: 0.2203 - val_output_1_loss: 0.1879 - val_output_2_loss: 0.0324
Epoch 72/100
49/49 [==============================] - 3s 53ms/step - loss: 0.1821 - output_1_loss: 0.1808 - output_2_loss: 0.0013 - val_loss: 0.2379 - val_output_1_loss: 0.2076 - val_output_2_loss: 0.0303
Epoch 73/100
49/49 [==============================] - 3s 53ms/step - loss: 0.1827 - output_1_loss: 0.1814 - output_2_loss: 0.0013 - val_loss: 0.2210 - val_output_1_loss: 0.1907 - val_output_2_loss: 0.0303
Epoch 74/100
49/49 [==============================] - 3s 53ms/step - loss: 0.1778 - output_1_loss: 0.1765 - output_2_loss: 0.0012 - val_loss: 0.2260 - val_output_1_loss: 0.1936 - val_output_2_loss: 0.0323
Epoch 75/100
49/49 [==============================] - 3s 53ms/step - loss: 0.1769 - output_1_loss: 0.1757 - output_2_loss: 0.0012 - val_loss: 0.2148 - val_output_1_loss: 0.1827 - val_output_2_loss: 0.0321
Epoch 76/100
49/49 [==============================] - 3s 53ms/step - loss: 0.1808 - output_1_loss: 0.1795 - output_2_loss: 0.0013 - val_loss: 0.2261 - val_output_1_loss: 0.1945 - val_output_2_loss: 0.0316
Epoch 77/100
49/49 [==============================] - 3s 53ms/step - loss: 0.1792 - output_1_loss: 0.1780 - output_2_loss: 0.0012 - val_loss: 0.2156 - val_output_1_loss: 0.1830 - val_output_2_loss: 0.0327
Epoch 78/100
49/49 [==============================] - 3s 53ms/step - loss: 0.1797 - output_1_loss: 0.1786 - output_2_loss: 0.0011 - val_loss: 0.2165 - val_output_1_loss: 0.1837 - val_output_2_loss: 0.0327
Epoch 79/100
49/49 [==============================] - 3s 53ms/step - loss: 0.1790 - output_1_loss: 0.1779 - output_2_loss: 0.0011 - val_loss: 0.2168 - val_output_1_loss: 0.1841 - val_output_2_loss: 0.0326
Epoch 80/100
49/49 [==============================] - 3s 53ms/step - loss: 0.1776 - output_1_loss: 0.1764 - output_2_loss: 0.0012 - val_loss: 0.2219 - val_output_1_loss: 0.1889 - val_output_2_loss: 0.0330
Epoch 81/100
49/49 [==============================] - 3s 53ms/step - loss: 0.1747 - output_1_loss: 0.1736 - output_2_loss: 0.0011 - val_loss: 0.2224 - val_output_1_loss: 0.1889 - val_output_2_loss: 0.0335
Epoch 82/100
49/49 [==============================] - 3s 53ms/step - loss: 0.1797 - output_1_loss: 0.1786 - output_2_loss: 0.0012 - val_loss: 0.2162 - val_output_1_loss: 0.1834 - val_output_2_loss: 0.0328
Epoch 83/100
49/49 [==============================] - 3s 53ms/step - loss: 0.1711 - output_1_loss: 0.1701 - output_2_loss: 9.6944e-04 - val_loss: 0.2076 - val_output_1_loss: 0.1751 - val_output_2_loss: 0.0325
Epoch 84/100
49/49 [==============================] - 3s 53ms/step - loss: 0.1738 - output_1_loss: 0.1727 - output_2_loss: 0.0010 - val_loss: 0.2097 - val_output_1_loss: 0.1772 - val_output_2_loss: 0.0325
Epoch 85/100
49/49 [==============================] - 3s 53ms/step - loss: 0.1697 - output_1_loss: 0.1687 - output_2_loss: 0.0010 - val_loss: 0.2097 - val_output_1_loss: 0.1765 - val_output_2_loss: 0.0332
Epoch 86/100
49/49 [==============================] - 3s 53ms/step - loss: 0.1738 - output_1_loss: 0.1727 - output_2_loss: 0.0010 - val_loss: 0.2493 - val_output_1_loss: 0.2183 - val_output_2_loss: 0.0310
Epoch 87/100
49/49 [==============================] - 3s 53ms/step - loss: 0.1707 - output_1_loss: 0.1697 - output_2_loss: 0.0011 - val_loss: 0.2673 - val_output_1_loss: 0.2368 - val_output_2_loss: 0.0305
Epoch 88/100
49/49 [==============================] - 3s 53ms/step - loss: 0.1693 - output_1_loss: 0.1683 - output_2_loss: 9.9187e-04 - val_loss: 0.2235 - val_output_1_loss: 0.1919 - val_output_2_loss: 0.0316
Epoch 89/100
49/49 [==============================] - 3s 53ms/step - loss: 0.1720 - output_1_loss: 0.1710 - output_2_loss: 0.0010 - val_loss: 0.2169 - val_output_1_loss: 0.1830 - val_output_2_loss: 0.0339
Epoch 90/100
49/49 [==============================] - 3s 53ms/step - loss: 0.1671 - output_1_loss: 0.1661 - output_2_loss: 9.4894e-04 - val_loss: 0.2139 - val_output_1_loss: 0.1789 - val_output_2_loss: 0.0350
Epoch 91/100
49/49 [==============================] - 3s 53ms/step - loss: 0.1702 - output_1_loss: 0.1693 - output_2_loss: 8.5859e-04 - val_loss: 0.2259 - val_output_1_loss: 0.1936 - val_output_2_loss: 0.0324
Epoch 92/100
49/49 [==============================] - 3s 53ms/step - loss: 0.1705 - output_1_loss: 0.1696 - output_2_loss: 9.2976e-04 - val_loss: 0.2247 - val_output_1_loss: 0.1920 - val_output_2_loss: 0.0327
Epoch 93/100
49/49 [==============================] - 3s 53ms/step - loss: 0.1677 - output_1_loss: 0.1667 - output_2_loss: 9.4122e-04 - val_loss: 0.2231 - val_output_1_loss: 0.1888 - val_output_2_loss: 0.0342
Epoch 94/100
49/49 [==============================] - 3s 53ms/step - loss: 0.1675 - output_1_loss: 0.1666 - output_2_loss: 9.1578e-04 - val_loss: 0.2124 - val_output_1_loss: 0.1790 - val_output_2_loss: 0.0334
Epoch 95/100
49/49 [==============================] - 3s 53ms/step - loss: 0.1675 - output_1_loss: 0.1666 - output_2_loss: 8.9786e-04 - val_loss: 0.2049 - val_output_1_loss: 0.1725 - val_output_2_loss: 0.0324
Epoch 96/100
49/49 [==============================] - 3s 53ms/step - loss: 0.1653 - output_1_loss: 0.1644 - output_2_loss: 8.6616e-04 - val_loss: 0.2230 - val_output_1_loss: 0.1915 - val_output_2_loss: 0.0316
Epoch 97/100
49/49 [==============================] - 3s 53ms/step - loss: 0.1633 - output_1_loss: 0.1624 - output_2_loss: 8.6741e-04 - val_loss: 0.2168 - val_output_1_loss: 0.1843 - val_output_2_loss: 0.0325
Epoch 98/100
49/49 [==============================] - 3s 53ms/step - loss: 0.1645 - output_1_loss: 0.1637 - output_2_loss: 8.7361e-04 - val_loss: 0.2225 - val_output_1_loss: 0.1878 - val_output_2_loss: 0.0347
Epoch 99/100
49/49 [==============================] - 3s 53ms/step - loss: 0.1646 - output_1_loss: 0.1637 - output_2_loss: 8.6288e-04 - val_loss: 0.2040 - val_output_1_loss: 0.1722 - val_output_2_loss: 0.0317
Epoch 100/100
49/49 [==============================] - 3s 53ms/step - loss: 0.1640 - output_1_loss: 0.1631 - output_2_loss: 8.6761e-04 - val_loss: 0.2059 - val_output_1_loss: 0.1741 - val_output_2_loss: 0.0318
Keras weights file (<HDF5 file "variables.h5" (mode r+)>) saving:
...layers
......average_pooling2d
.........vars
......average_pooling2d_1
.........vars
......average_pooling2d_2
.........vars
......conv2d
.........vars
............0
............1
......conv2d_1
.........vars
............0
............1
......conv2d_2
.........vars
............0
............1
......dense
.........vars
............0
............1
......dense_1
.........vars
............0
............1
......dense_2
.........vars
............0
............1
......dense_3
.........vars
............0
............1
......dropout
.........vars
......flatten
.........vars
......input_layer
.........vars
...metrics
......mean
.........vars
............0
............1
......mean_1
.........vars
............0
............1
......mean_2
.........vars
............0
............1
...optimizer
......vars
.........0
.........1
.........10
.........11
.........12
.........13
.........14
.........15
.........16
.........17
.........18
.........19
.........2
.........20
.........21
.........22
.........23
.........24
.........25
.........26
.........27
.........28
.........3
.........4
.........5
.........6
.........7
.........8
.........9
...vars
Keras model archive saving:
File Name                                             Modified             Size
variables.h5                                   2022-11-30 17:35:08     30822612
config.json                                    2022-11-30 17:35:08         5811
metadata.json                                  2022-11-30 17:35:08           64
33/33 [==============================] - 1s 11ms/step
accuracy_score  > 0.965
mean_absolute_error 0.1664463296964315 mean_squared_error 0.12277427901511359

