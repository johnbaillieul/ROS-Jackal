Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 250, 250, 2  0           []                               
                                )]                                                                
                                                                                                  
 conv2d (Conv2D)                (None, 248, 248, 64  1216        ['input_1[0][0]']                
                                )                                                                 
                                                                                                  
 average_pooling2d (AveragePool  (None, 124, 124, 64  0          ['conv2d[0][0]']                 
 ing2D)                         )                                                                 
                                                                                                  
 conv2d_1 (Conv2D)              (None, 122, 122, 32  18464       ['average_pooling2d[0][0]']      
                                )                                                                 
                                                                                                  
 average_pooling2d_1 (AveragePo  (None, 61, 61, 32)  0           ['conv2d_1[0][0]']               
 oling2D)                                                                                         
                                                                                                  
 conv2d_2 (Conv2D)              (None, 59, 59, 16)   4624        ['average_pooling2d_1[0][0]']    
                                                                                                  
 average_pooling2d_2 (AveragePo  (None, 29, 29, 16)  0           ['conv2d_2[0][0]']               
 oling2D)                                                                                         
                                                                                                  
 flatten (Flatten)              (None, 13456)        0           ['average_pooling2d_2[0][0]']    
                                                                                                  
 dense (Dense)                  (None, 128)          1722496     ['flatten[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 225)          29025       ['dense[0][0]']                  
                                                                                                  
 dropout (Dropout)              (None, 225)          0           ['dense_1[0][0]']                
                                                                                                  
 output_1 (Dense)               (None, 5)            1130        ['dropout[0][0]']                
                                                                                                  
 output_2 (Dense)               (None, 5)            645         ['dense[0][0]']                  
                                                                                                  
==================================================================================================
Total params: 1,777,600
Trainable params: 1,777,600
Non-trainable params: 0
__________________________________________________________________________________________________
None
Epoch 1/100
2022-11-30 17:26:04.247220: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100
2022-11-30 17:26:05.457087: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2022-11-30 17:26:05.460928: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f8924013350 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-11-30 17:26:05.460964: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA RTX A5000, Compute Capability 8.6
2022-11-30 17:26:05.460974: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): NVIDIA RTX A5000, Compute Capability 8.6
2022-11-30 17:26:05.460982: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (2): NVIDIA RTX A5000, Compute Capability 8.6
2022-11-30 17:26:05.460990: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (3): NVIDIA RTX A5000, Compute Capability 8.6
2022-11-30 17:26:05.467850: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-11-30 17:26:05.567805: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
49/49 [==============================] - 6s 49ms/step - loss: 1.9531 - output_1_loss: 1.5832 - output_2_loss: 0.3699 - val_loss: 0.9538 - val_output_1_loss: 0.7641 - val_output_2_loss: 0.1896
Epoch 2/100
49/49 [==============================] - 2s 35ms/step - loss: 0.9647 - output_1_loss: 0.8025 - output_2_loss: 0.1623 - val_loss: 0.7081 - val_output_1_loss: 0.5617 - val_output_2_loss: 0.1464
Epoch 3/100
49/49 [==============================] - 2s 36ms/step - loss: 0.7555 - output_1_loss: 0.6386 - output_2_loss: 0.1169 - val_loss: 0.6284 - val_output_1_loss: 0.5146 - val_output_2_loss: 0.1138
Epoch 4/100
49/49 [==============================] - 2s 36ms/step - loss: 0.6457 - output_1_loss: 0.5590 - output_2_loss: 0.0867 - val_loss: 0.5347 - val_output_1_loss: 0.4417 - val_output_2_loss: 0.0930
Epoch 5/100
49/49 [==============================] - 2s 36ms/step - loss: 0.5611 - output_1_loss: 0.4962 - output_2_loss: 0.0649 - val_loss: 0.5345 - val_output_1_loss: 0.4452 - val_output_2_loss: 0.0893
Epoch 6/100
49/49 [==============================] - 2s 36ms/step - loss: 0.5087 - output_1_loss: 0.4574 - output_2_loss: 0.0513 - val_loss: 0.4639 - val_output_1_loss: 0.3953 - val_output_2_loss: 0.0686
Epoch 7/100
49/49 [==============================] - 2s 36ms/step - loss: 0.4574 - output_1_loss: 0.4161 - output_2_loss: 0.0413 - val_loss: 0.4237 - val_output_1_loss: 0.3632 - val_output_2_loss: 0.0605
Epoch 8/100
49/49 [==============================] - 2s 36ms/step - loss: 0.4347 - output_1_loss: 0.3993 - output_2_loss: 0.0354 - val_loss: 0.3996 - val_output_1_loss: 0.3470 - val_output_2_loss: 0.0526
Epoch 9/100
49/49 [==============================] - 2s 36ms/step - loss: 0.4044 - output_1_loss: 0.3751 - output_2_loss: 0.0292 - val_loss: 0.3991 - val_output_1_loss: 0.3421 - val_output_2_loss: 0.0569
Epoch 10/100
49/49 [==============================] - 2s 36ms/step - loss: 0.3960 - output_1_loss: 0.3701 - output_2_loss: 0.0259 - val_loss: 0.3799 - val_output_1_loss: 0.3295 - val_output_2_loss: 0.0504
Epoch 11/100
49/49 [==============================] - 2s 36ms/step - loss: 0.3765 - output_1_loss: 0.3530 - output_2_loss: 0.0235 - val_loss: 0.4053 - val_output_1_loss: 0.3587 - val_output_2_loss: 0.0466
Epoch 12/100
49/49 [==============================] - 2s 36ms/step - loss: 0.3568 - output_1_loss: 0.3371 - output_2_loss: 0.0197 - val_loss: 0.3585 - val_output_1_loss: 0.3156 - val_output_2_loss: 0.0429
Epoch 13/100
49/49 [==============================] - 2s 36ms/step - loss: 0.3408 - output_1_loss: 0.3239 - output_2_loss: 0.0169 - val_loss: 0.3674 - val_output_1_loss: 0.3197 - val_output_2_loss: 0.0477
Epoch 14/100
49/49 [==============================] - 2s 36ms/step - loss: 0.3324 - output_1_loss: 0.3176 - output_2_loss: 0.0148 - val_loss: 0.3268 - val_output_1_loss: 0.2849 - val_output_2_loss: 0.0419
Epoch 15/100
49/49 [==============================] - 2s 36ms/step - loss: 0.3181 - output_1_loss: 0.3048 - output_2_loss: 0.0133 - val_loss: 0.3137 - val_output_1_loss: 0.2731 - val_output_2_loss: 0.0406
Epoch 16/100
49/49 [==============================] - 2s 36ms/step - loss: 0.3068 - output_1_loss: 0.2946 - output_2_loss: 0.0123 - val_loss: 0.3185 - val_output_1_loss: 0.2786 - val_output_2_loss: 0.0399
Epoch 17/100
49/49 [==============================] - 2s 36ms/step - loss: 0.2954 - output_1_loss: 0.2845 - output_2_loss: 0.0108 - val_loss: 0.3300 - val_output_1_loss: 0.2909 - val_output_2_loss: 0.0391
Epoch 18/100
49/49 [==============================] - 2s 36ms/step - loss: 0.2925 - output_1_loss: 0.2825 - output_2_loss: 0.0100 - val_loss: 0.3260 - val_output_1_loss: 0.2865 - val_output_2_loss: 0.0396
Epoch 19/100
49/49 [==============================] - 2s 36ms/step - loss: 0.2809 - output_1_loss: 0.2720 - output_2_loss: 0.0088 - val_loss: 0.2923 - val_output_1_loss: 0.2548 - val_output_2_loss: 0.0375
Epoch 20/100
49/49 [==============================] - 2s 36ms/step - loss: 0.2737 - output_1_loss: 0.2651 - output_2_loss: 0.0086 - val_loss: 0.3101 - val_output_1_loss: 0.2722 - val_output_2_loss: 0.0379
Epoch 21/100
49/49 [==============================] - 2s 36ms/step - loss: 0.2656 - output_1_loss: 0.2575 - output_2_loss: 0.0081 - val_loss: 0.2861 - val_output_1_loss: 0.2502 - val_output_2_loss: 0.0359
Epoch 22/100
49/49 [==============================] - 2s 36ms/step - loss: 0.2720 - output_1_loss: 0.2642 - output_2_loss: 0.0078 - val_loss: 0.3050 - val_output_1_loss: 0.2680 - val_output_2_loss: 0.0370
Epoch 23/100
49/49 [==============================] - 2s 36ms/step - loss: 0.2577 - output_1_loss: 0.2514 - output_2_loss: 0.0063 - val_loss: 0.2840 - val_output_1_loss: 0.2479 - val_output_2_loss: 0.0361
Epoch 24/100
49/49 [==============================] - 2s 36ms/step - loss: 0.2597 - output_1_loss: 0.2534 - output_2_loss: 0.0063 - val_loss: 0.2887 - val_output_1_loss: 0.2523 - val_output_2_loss: 0.0363
Epoch 25/100
49/49 [==============================] - 2s 36ms/step - loss: 0.2534 - output_1_loss: 0.2477 - output_2_loss: 0.0057 - val_loss: 0.2821 - val_output_1_loss: 0.2465 - val_output_2_loss: 0.0356
Epoch 26/100
49/49 [==============================] - 2s 36ms/step - loss: 0.2539 - output_1_loss: 0.2482 - output_2_loss: 0.0057 - val_loss: 0.3068 - val_output_1_loss: 0.2695 - val_output_2_loss: 0.0373
Epoch 27/100
49/49 [==============================] - 2s 36ms/step - loss: 0.2423 - output_1_loss: 0.2369 - output_2_loss: 0.0053 - val_loss: 0.2870 - val_output_1_loss: 0.2508 - val_output_2_loss: 0.0363
Epoch 28/100
49/49 [==============================] - 2s 36ms/step - loss: 0.2411 - output_1_loss: 0.2362 - output_2_loss: 0.0049 - val_loss: 0.2751 - val_output_1_loss: 0.2383 - val_output_2_loss: 0.0369
Epoch 29/100
49/49 [==============================] - 2s 36ms/step - loss: 0.2354 - output_1_loss: 0.2306 - output_2_loss: 0.0048 - val_loss: 0.2889 - val_output_1_loss: 0.2511 - val_output_2_loss: 0.0378
Epoch 30/100
49/49 [==============================] - 2s 36ms/step - loss: 0.2336 - output_1_loss: 0.2290 - output_2_loss: 0.0046 - val_loss: 0.2884 - val_output_1_loss: 0.2506 - val_output_2_loss: 0.0378
Epoch 31/100
49/49 [==============================] - 2s 36ms/step - loss: 0.2311 - output_1_loss: 0.2267 - output_2_loss: 0.0044 - val_loss: 0.2793 - val_output_1_loss: 0.2423 - val_output_2_loss: 0.0371
Epoch 32/100
49/49 [==============================] - 2s 36ms/step - loss: 0.2371 - output_1_loss: 0.2327 - output_2_loss: 0.0043 - val_loss: 0.3001 - val_output_1_loss: 0.2665 - val_output_2_loss: 0.0336
Epoch 33/100
49/49 [==============================] - 2s 36ms/step - loss: 0.2339 - output_1_loss: 0.2301 - output_2_loss: 0.0039 - val_loss: 0.2803 - val_output_1_loss: 0.2440 - val_output_2_loss: 0.0363
Epoch 34/100
49/49 [==============================] - 2s 36ms/step - loss: 0.2258 - output_1_loss: 0.2223 - output_2_loss: 0.0036 - val_loss: 0.2602 - val_output_1_loss: 0.2235 - val_output_2_loss: 0.0368
Epoch 35/100
49/49 [==============================] - 2s 36ms/step - loss: 0.2253 - output_1_loss: 0.2218 - output_2_loss: 0.0035 - val_loss: 0.2569 - val_output_1_loss: 0.2228 - val_output_2_loss: 0.0341
Epoch 36/100
49/49 [==============================] - 2s 36ms/step - loss: 0.2239 - output_1_loss: 0.2205 - output_2_loss: 0.0035 - val_loss: 0.2614 - val_output_1_loss: 0.2244 - val_output_2_loss: 0.0370
Epoch 37/100
49/49 [==============================] - 2s 36ms/step - loss: 0.2169 - output_1_loss: 0.2138 - output_2_loss: 0.0032 - val_loss: 0.2570 - val_output_1_loss: 0.2234 - val_output_2_loss: 0.0336
Epoch 38/100
49/49 [==============================] - 2s 36ms/step - loss: 0.2121 - output_1_loss: 0.2091 - output_2_loss: 0.0030 - val_loss: 0.2532 - val_output_1_loss: 0.2194 - val_output_2_loss: 0.0338
Epoch 39/100
49/49 [==============================] - 2s 36ms/step - loss: 0.2118 - output_1_loss: 0.2088 - output_2_loss: 0.0030 - val_loss: 0.2586 - val_output_1_loss: 0.2272 - val_output_2_loss: 0.0314
Epoch 40/100
49/49 [==============================] - 2s 36ms/step - loss: 0.2097 - output_1_loss: 0.2069 - output_2_loss: 0.0029 - val_loss: 0.2545 - val_output_1_loss: 0.2205 - val_output_2_loss: 0.0340
Epoch 41/100
49/49 [==============================] - 2s 36ms/step - loss: 0.2101 - output_1_loss: 0.2072 - output_2_loss: 0.0028 - val_loss: 0.2496 - val_output_1_loss: 0.2164 - val_output_2_loss: 0.0332
Epoch 42/100
49/49 [==============================] - 2s 36ms/step - loss: 0.2064 - output_1_loss: 0.2036 - output_2_loss: 0.0028 - val_loss: 0.2842 - val_output_1_loss: 0.2490 - val_output_2_loss: 0.0352
Epoch 43/100
49/49 [==============================] - 2s 36ms/step - loss: 0.2114 - output_1_loss: 0.2088 - output_2_loss: 0.0026 - val_loss: 0.2449 - val_output_1_loss: 0.2115 - val_output_2_loss: 0.0334
Epoch 44/100
49/49 [==============================] - 2s 36ms/step - loss: 0.2093 - output_1_loss: 0.2068 - output_2_loss: 0.0025 - val_loss: 0.2685 - val_output_1_loss: 0.2323 - val_output_2_loss: 0.0362
Epoch 45/100
49/49 [==============================] - 2s 36ms/step - loss: 0.2095 - output_1_loss: 0.2068 - output_2_loss: 0.0027 - val_loss: 0.2451 - val_output_1_loss: 0.2121 - val_output_2_loss: 0.0330
Epoch 46/100
49/49 [==============================] - 2s 36ms/step - loss: 0.2022 - output_1_loss: 0.1998 - output_2_loss: 0.0025 - val_loss: 0.2559 - val_output_1_loss: 0.2215 - val_output_2_loss: 0.0344
Epoch 47/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1985 - output_1_loss: 0.1962 - output_2_loss: 0.0023 - val_loss: 0.2472 - val_output_1_loss: 0.2114 - val_output_2_loss: 0.0357
Epoch 48/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1980 - output_1_loss: 0.1958 - output_2_loss: 0.0022 - val_loss: 0.2718 - val_output_1_loss: 0.2392 - val_output_2_loss: 0.0327
Epoch 49/100
49/49 [==============================] - 2s 36ms/step - loss: 0.2017 - output_1_loss: 0.1995 - output_2_loss: 0.0022 - val_loss: 0.2541 - val_output_1_loss: 0.2201 - val_output_2_loss: 0.0340
Epoch 50/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1983 - output_1_loss: 0.1963 - output_2_loss: 0.0020 - val_loss: 0.2518 - val_output_1_loss: 0.2146 - val_output_2_loss: 0.0372
Epoch 51/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1946 - output_1_loss: 0.1925 - output_2_loss: 0.0021 - val_loss: 0.2545 - val_output_1_loss: 0.2204 - val_output_2_loss: 0.0341
Epoch 52/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1896 - output_1_loss: 0.1876 - output_2_loss: 0.0020 - val_loss: 0.2617 - val_output_1_loss: 0.2284 - val_output_2_loss: 0.0332
Epoch 53/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1935 - output_1_loss: 0.1917 - output_2_loss: 0.0018 - val_loss: 0.2475 - val_output_1_loss: 0.2113 - val_output_2_loss: 0.0362
Epoch 54/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1881 - output_1_loss: 0.1863 - output_2_loss: 0.0018 - val_loss: 0.2468 - val_output_1_loss: 0.2100 - val_output_2_loss: 0.0369
Epoch 55/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1891 - output_1_loss: 0.1874 - output_2_loss: 0.0018 - val_loss: 0.2497 - val_output_1_loss: 0.2145 - val_output_2_loss: 0.0352
Epoch 56/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1871 - output_1_loss: 0.1853 - output_2_loss: 0.0017 - val_loss: 0.2376 - val_output_1_loss: 0.2045 - val_output_2_loss: 0.0331
Epoch 57/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1855 - output_1_loss: 0.1837 - output_2_loss: 0.0017 - val_loss: 0.2487 - val_output_1_loss: 0.2104 - val_output_2_loss: 0.0383
Epoch 58/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1886 - output_1_loss: 0.1868 - output_2_loss: 0.0019 - val_loss: 0.2363 - val_output_1_loss: 0.2020 - val_output_2_loss: 0.0343
Epoch 59/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1865 - output_1_loss: 0.1850 - output_2_loss: 0.0016 - val_loss: 0.2351 - val_output_1_loss: 0.2002 - val_output_2_loss: 0.0349
Epoch 60/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1821 - output_1_loss: 0.1805 - output_2_loss: 0.0016 - val_loss: 0.2414 - val_output_1_loss: 0.2052 - val_output_2_loss: 0.0362
Epoch 61/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1846 - output_1_loss: 0.1829 - output_2_loss: 0.0017 - val_loss: 0.2401 - val_output_1_loss: 0.2031 - val_output_2_loss: 0.0370
Epoch 62/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1860 - output_1_loss: 0.1844 - output_2_loss: 0.0016 - val_loss: 0.2449 - val_output_1_loss: 0.2096 - val_output_2_loss: 0.0353
Epoch 63/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1806 - output_1_loss: 0.1791 - output_2_loss: 0.0015 - val_loss: 0.2399 - val_output_1_loss: 0.2060 - val_output_2_loss: 0.0339
Epoch 64/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1801 - output_1_loss: 0.1784 - output_2_loss: 0.0016 - val_loss: 0.2301 - val_output_1_loss: 0.1959 - val_output_2_loss: 0.0341
Epoch 65/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1843 - output_1_loss: 0.1828 - output_2_loss: 0.0015 - val_loss: 0.2387 - val_output_1_loss: 0.2033 - val_output_2_loss: 0.0354
Epoch 66/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1782 - output_1_loss: 0.1768 - output_2_loss: 0.0014 - val_loss: 0.2360 - val_output_1_loss: 0.2028 - val_output_2_loss: 0.0332
Epoch 67/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1782 - output_1_loss: 0.1768 - output_2_loss: 0.0014 - val_loss: 0.2541 - val_output_1_loss: 0.2193 - val_output_2_loss: 0.0348
Epoch 68/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1769 - output_1_loss: 0.1755 - output_2_loss: 0.0014 - val_loss: 0.2343 - val_output_1_loss: 0.2006 - val_output_2_loss: 0.0337
Epoch 69/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1781 - output_1_loss: 0.1767 - output_2_loss: 0.0014 - val_loss: 0.2452 - val_output_1_loss: 0.2090 - val_output_2_loss: 0.0363
Epoch 70/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1799 - output_1_loss: 0.1786 - output_2_loss: 0.0013 - val_loss: 0.2402 - val_output_1_loss: 0.2047 - val_output_2_loss: 0.0356
Epoch 71/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1733 - output_1_loss: 0.1720 - output_2_loss: 0.0013 - val_loss: 0.2364 - val_output_1_loss: 0.2030 - val_output_2_loss: 0.0334
Epoch 72/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1746 - output_1_loss: 0.1733 - output_2_loss: 0.0014 - val_loss: 0.2409 - val_output_1_loss: 0.2067 - val_output_2_loss: 0.0342
Epoch 73/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1750 - output_1_loss: 0.1738 - output_2_loss: 0.0012 - val_loss: 0.2350 - val_output_1_loss: 0.1985 - val_output_2_loss: 0.0365
Epoch 74/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1725 - output_1_loss: 0.1713 - output_2_loss: 0.0012 - val_loss: 0.2327 - val_output_1_loss: 0.1974 - val_output_2_loss: 0.0353
Epoch 75/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1690 - output_1_loss: 0.1678 - output_2_loss: 0.0012 - val_loss: 0.2290 - val_output_1_loss: 0.1946 - val_output_2_loss: 0.0345
Epoch 76/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1705 - output_1_loss: 0.1694 - output_2_loss: 0.0011 - val_loss: 0.2415 - val_output_1_loss: 0.2045 - val_output_2_loss: 0.0370
Epoch 77/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1695 - output_1_loss: 0.1683 - output_2_loss: 0.0012 - val_loss: 0.2322 - val_output_1_loss: 0.1963 - val_output_2_loss: 0.0360
Epoch 78/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1690 - output_1_loss: 0.1678 - output_2_loss: 0.0012 - val_loss: 0.2250 - val_output_1_loss: 0.1902 - val_output_2_loss: 0.0348
Epoch 79/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1720 - output_1_loss: 0.1709 - output_2_loss: 0.0011 - val_loss: 0.2246 - val_output_1_loss: 0.1910 - val_output_2_loss: 0.0336
Epoch 80/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1689 - output_1_loss: 0.1679 - output_2_loss: 0.0011 - val_loss: 0.2244 - val_output_1_loss: 0.1884 - val_output_2_loss: 0.0360
Epoch 81/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1713 - output_1_loss: 0.1701 - output_2_loss: 0.0012 - val_loss: 0.2271 - val_output_1_loss: 0.1924 - val_output_2_loss: 0.0347
Epoch 82/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1673 - output_1_loss: 0.1663 - output_2_loss: 0.0010 - val_loss: 0.2226 - val_output_1_loss: 0.1866 - val_output_2_loss: 0.0360
Epoch 83/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1644 - output_1_loss: 0.1634 - output_2_loss: 9.7868e-04 - val_loss: 0.2253 - val_output_1_loss: 0.1900 - val_output_2_loss: 0.0353
Epoch 84/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1664 - output_1_loss: 0.1654 - output_2_loss: 0.0010 - val_loss: 0.2251 - val_output_1_loss: 0.1899 - val_output_2_loss: 0.0352
Epoch 85/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1670 - output_1_loss: 0.1660 - output_2_loss: 9.3891e-04 - val_loss: 0.2361 - val_output_1_loss: 0.1998 - val_output_2_loss: 0.0364
Epoch 86/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1642 - output_1_loss: 0.1632 - output_2_loss: 0.0010 - val_loss: 0.2254 - val_output_1_loss: 0.1898 - val_output_2_loss: 0.0357
Epoch 87/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1647 - output_1_loss: 0.1636 - output_2_loss: 0.0010 - val_loss: 0.2485 - val_output_1_loss: 0.2160 - val_output_2_loss: 0.0325
Epoch 88/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1654 - output_1_loss: 0.1645 - output_2_loss: 9.3934e-04 - val_loss: 0.2228 - val_output_1_loss: 0.1880 - val_output_2_loss: 0.0347
Epoch 89/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1621 - output_1_loss: 0.1612 - output_2_loss: 8.9044e-04 - val_loss: 0.2224 - val_output_1_loss: 0.1886 - val_output_2_loss: 0.0338
Epoch 90/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1646 - output_1_loss: 0.1637 - output_2_loss: 8.9719e-04 - val_loss: 0.2178 - val_output_1_loss: 0.1818 - val_output_2_loss: 0.0360
Epoch 91/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1601 - output_1_loss: 0.1592 - output_2_loss: 9.0081e-04 - val_loss: 0.2213 - val_output_1_loss: 0.1830 - val_output_2_loss: 0.0383
Epoch 92/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1608 - output_1_loss: 0.1600 - output_2_loss: 8.4505e-04 - val_loss: 0.2198 - val_output_1_loss: 0.1832 - val_output_2_loss: 0.0366
Epoch 93/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1612 - output_1_loss: 0.1603 - output_2_loss: 8.7269e-04 - val_loss: 0.2288 - val_output_1_loss: 0.1926 - val_output_2_loss: 0.0362
Epoch 94/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1566 - output_1_loss: 0.1557 - output_2_loss: 9.0081e-04 - val_loss: 0.2229 - val_output_1_loss: 0.1896 - val_output_2_loss: 0.0333
Epoch 95/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1617 - output_1_loss: 0.1609 - output_2_loss: 8.5953e-04 - val_loss: 0.2131 - val_output_1_loss: 0.1787 - val_output_2_loss: 0.0344
Epoch 96/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1581 - output_1_loss: 0.1572 - output_2_loss: 8.4871e-04 - val_loss: 0.2168 - val_output_1_loss: 0.1822 - val_output_2_loss: 0.0346
Epoch 97/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1600 - output_1_loss: 0.1591 - output_2_loss: 8.8820e-04 - val_loss: 0.2277 - val_output_1_loss: 0.1928 - val_output_2_loss: 0.0349
Epoch 98/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1583 - output_1_loss: 0.1575 - output_2_loss: 8.0228e-04 - val_loss: 0.2254 - val_output_1_loss: 0.1905 - val_output_2_loss: 0.0348
Epoch 99/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1576 - output_1_loss: 0.1567 - output_2_loss: 8.7702e-04 - val_loss: 0.2160 - val_output_1_loss: 0.1826 - val_output_2_loss: 0.0334
Epoch 100/100
49/49 [==============================] - 2s 36ms/step - loss: 0.1555 - output_1_loss: 0.1547 - output_2_loss: 8.1080e-04 - val_loss: 0.2162 - val_output_1_loss: 0.1806 - val_output_2_loss: 0.0356
Keras weights file (<HDF5 file "variables.h5" (mode r+)>) saving:
...layers
......average_pooling2d
.........vars
......average_pooling2d_1
.........vars
......average_pooling2d_2
.........vars
......conv2d
.........vars
............0
............1
......conv2d_1
.........vars
............0
............1
......conv2d_2
.........vars
............0
............1
......dense
.........vars
............0
............1
......dense_1
.........vars
............0
............1
......dense_2
.........vars
............0
............1
......dense_3
.........vars
............0
............1
......dropout
.........vars
......flatten
.........vars
......input_layer
.........vars
...metrics
......mean
.........vars
............0
............1
......mean_1
.........vars
............0
............1
......mean_2
.........vars
............0
............1
...optimizer
......vars
.........0
.........1
.........10
.........11
.........12
.........13
.........14
.........15
.........16
.........17
.........18
.........19
.........2
.........20
.........21
.........22
.........23
.........24
.........25
.........26
.........27
.........28
.........3
.........4
.........5
.........6
.........7
.........8
.........9
...vars
Keras model archive saving:
File Name                                             Modified             Size
variables.h5                                   2022-11-30 17:29:04     21385428
config.json                                    2022-11-30 17:29:04         5811
metadata.json                                  2022-11-30 17:29:04           64
33/33 [==============================] - 0s 8ms/step
accuracy_score  > 0.961
mean_absolute_error 0.1741419385499925 mean_squared_error 0.1409209767173759

